{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits saved to /home/sastocke/nnUNet/nnUNet_preprocessed/Dataset060_DiscoandDirvsAvgHannumLV/splits_final.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def specific_split_json_file(dataset_name):\n",
    "    dataset_folder = os.path.join(\"/home/sastocke/nnUNet/nnUNet_raw\", dataset_name, \"imagesTr\")\n",
    "    all_files = [f.split(\"_000\")[0] for f in os.listdir(dataset_folder) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "    # Define all volunteers (excluding Volunteer 03)\n",
    "    volunteers = [f\"{i:02}\" for i in range(1, 13) if i != 3]  # '01' to '12', excluding '03'\n",
    "\n",
    "    # Select the first 5 volunteers for validation\n",
    "    validation_volunteers = volunteers[:5]  # ['01', '02', '04', '05', '06']\n",
    "\n",
    "    splits = []\n",
    "    for val_vol in validation_volunteers:\n",
    "        # Training set: all volunteers except the validation volunteer and Volunteer 03\n",
    "        train_vols = [v for v in volunteers if v != val_vol]\n",
    "        train_ids = [f for f in all_files if any(f\"Volunteer_{v}_\" in f for v in train_vols)]\n",
    "\n",
    "        #For disco and dirvsavg differences, only want to valiate on dirvsaverages\n",
    "        val_ids = [f for f in all_files if f.startswith(\"Hannum_Volunteer_\") and f\"Volunteer_{val_vol}_\" in f and f'r0' in f]\n",
    "\n",
    "        # Ensure filenames are clean\n",
    "        train_ids = [f.replace(\"__\", \"_\") for f in train_ids]\n",
    "        val_ids = [f.replace(\"__\", \"_\") for f in val_ids]\n",
    "\n",
    "        splits.append({\"train\": train_ids, \"val\": val_ids})\n",
    "\n",
    "    # Save the splits_final.json file\n",
    "    output_path = os.path.join(\"/home/sastocke/nnUNet/nnUNet_preprocessed\", dataset_name, \"splits_final.json\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(splits, f, indent=4)\n",
    "\n",
    "    print(f\"Splits saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_name = 'Dataset060_DiscoandDirvsAvgHannumLV'\n",
    "specific_split_json_file(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits: 5\n",
      "Split 1:\n",
      "  Train: 2976 samples\n",
      "  Val: 92 samples\n",
      "Split 2:\n",
      "  Train: 3056 samples\n",
      "  Val: 80 samples\n",
      "Split 3:\n",
      "  Train: 3104 samples\n",
      "  Val: 64 samples\n",
      "Split 4:\n",
      "  Train: 3008 samples\n",
      "  Val: 88 samples\n",
      "Split 5:\n",
      "  Train: 3136 samples\n",
      "  Val: 52 samples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to splits_final.json\n",
    "split_file_path = \"/home/sastocke/nnUNet/nnUNet_preprocessed/Dataset060_DiscoandDirvsAvgHannumLV/splits_final.json\"\n",
    "\n",
    "# Load and inspect the splits\n",
    "with open(split_file_path, \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "print(f\"Number of splits: {len(splits)}\")\n",
    "\n",
    "# Optionally, print details for each split\n",
    "for idx, split in enumerate(splits):\n",
    "    print(f\"Split {idx + 1}:\")\n",
    "    print(f\"  Train: {len(split['train'])} samples\")\n",
    "    print(f\"  Val: {len(split['val'])} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old splits: 11\n",
      "Old Split 1: Train 2592, Val 368\n",
      "Old Split 2: Train 2640, Val 320\n",
      "Old Split 3: Train 2704, Val 256\n",
      "Old Split 4: Train 2608, Val 352\n",
      "Old Split 5: Train 2752, Val 208\n",
      "Old Split 6: Train 2736, Val 224\n",
      "Old Split 7: Train 2720, Val 240\n",
      "Old Split 8: Train 2704, Val 256\n",
      "Old Split 9: Train 2752, Val 208\n",
      "Old Split 10: Train 2704, Val 256\n",
      "Old Split 11: Train 2688, Val 272\n",
      "\n",
      "New splits: {len(new_splits)}\n",
      "New Split 1: Train 2592, Val 368\n",
      "New Split 2: Train 2640, Val 320\n",
      "New Split 3: Train 2704, Val 256\n",
      "New Split 4: Train 2608, Val 352\n",
      "New Split 5: Train 2752, Val 208\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths to split files\n",
    "old_split_path = \"/home/sastocke/nnUNet/nnUNet_preprocessed/Dataset050_DataAugAllSpecifcNormLVOnly/old_splits_final.json\"  # Replace with the path of your 11-split file\n",
    "new_split_path = \"/home/sastocke/nnUNet/nnUNet_preprocessed/Dataset050_DataAugAllSpecifcNormLVOnly/splits_final.json\"\n",
    "\n",
    "# Load and print splits\n",
    "with open(old_split_path, \"r\") as f:\n",
    "    old_splits = json.load(f)\n",
    "\n",
    "with open(new_split_path, \"r\") as f:\n",
    "    new_splits = json.load(f)\n",
    "\n",
    "print(f\"Old splits: {len(old_splits)}\")\n",
    "for i, split in enumerate(old_splits):\n",
    "    print(f\"Old Split {i + 1}: Train {len(split['train'])}, Val {len(split['val'])}\")\n",
    "\n",
    "print(\"\\nNew splits: {len(new_splits)}\")\n",
    "for i, split in enumerate(new_splits):\n",
    "    print(f\"New Split {i + 1}: Train {len(split['train'])}, Val {len(split['val'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
