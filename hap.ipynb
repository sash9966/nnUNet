{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "sys.path.append('/Volumes/T7/Software')\n",
    "from cardpy.Sample_Data.Data_Paths import *\n",
    "from cardpy.Data_Import            import *\n",
    "from cardpy.Data_Sorting           import *\n",
    "from cardpy.Data_Processing.DTI    import *\n",
    "from cardpy.GUI_Tools              import IntERCOMS\n",
    "from cardpy.Colormaps              import *\n",
    "from cardpy.Data_Saving            import *\n",
    "from cardpy.Data_Processing.cDTI   import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "cDTI_cmaps     = cDTI_Colormaps_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60050/2526045862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmain_path\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0msample_Output_Folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNifTi_path\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*Interpolated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mheader_path\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*Interpolated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.header'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb_values_path\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*Interpolated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.bvals'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb_vectors_path\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*Interpolated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.bvecs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "main_path                = sample_Output_Folder()\n",
    "NifTi_path               = glob.glob(os.path.join(main_path, '*Interpolated', '*.nii'))[0]\n",
    "header_path              = glob.glob(os.path.join(main_path, '*Interpolated', '*.header'))[0]\n",
    "b_values_path            = glob.glob(os.path.join(main_path, '*Interpolated', '*.bvals'))[0]\n",
    "b_vectors_path           = glob.glob(os.path.join(main_path, '*Interpolated', '*.bvecs'))[0]\n",
    "\n",
    "Segmentaiton_Path        = os.path.join(main_path, '11_Segmentation')\n",
    "if os.path.isdir(Segmentaiton_Path) == False:\n",
    "    os.makedirs(Segmentaiton_Path)\n",
    "Quantiative_Results_Path = os.path.join(main_path, '12_Quantitative_Results')\n",
    "if os.path.isdir(Quantiative_Results_Path) == False:\n",
    "    os.makedirs(Quantiative_Results_Path)\n",
    "\n",
    "[matrix_stacked, b_vals_stacked, b_vecs_stacked, Header, _, _] = NifTi_Reader(NifTi_path, b_values_path, b_vectors_path, header_path)\n",
    "[matrix_sorted,  b_vals_sorted,  b_vecs_sorted]                = stacked2sorted(matrix_stacked, b_vals_stacked, b_vecs_stacked)\n",
    "[_, _, Eigenvectors, Standard_DTI_Metrics]                     = DTI_recon(matrix_sorted, b_vals_sorted, b_vecs_sorted, tensor_fit = 'NLLS')\n",
    "#[Endo_Centers, Endo_Axes, Epi_Centers, Epi_Axes]               = IntERCOMS.IntERCOMS_GUI(matrix_sorted[:, :, :, 0], Standard_DTI_Metrics['MD'], Eigenvectors['E1'], Line_Width = 1)\n",
    "#[myocardium_mask, NRRD2, NRRD1]                                = IntERCOMS.IntERCOMS_Mask_Making(matrix_sorted, Endo_Centers, Endo_Axes, Epi_Centers, Epi_Axes)\n",
    "#Save_NRRD_Segmentation(NRRD1, Header, Segmentaiton_Path, 'LV_Blood_Pool')\n",
    "#Save_NRRD_Segmentation(NRRD2, Header, Segmentaiton_Path, 'LV_Myocardium+Blood_Pool')\n",
    "\n",
    "myocardial_mask              = myocardium_mask\n",
    "# image = myocardial_mask\n",
    "num_interp_points            = 200\n",
    "#Tyler -> changed from medium to native, so it doesn't interoplate the mask, and doesn't smooth it out, double check:... tbd\n",
    "#Should get the raw masks, because trainnig is done on smoothed images so we compare the two outputs on the raw afterwards!\n",
    "smoothness_level             = 'Native'\n",
    "Helix_Angle_Filter_Settings  = dict()\n",
    "Helix_Angle_Filter_Settings['Linear Filter: Outlier StDev']      = 1\n",
    "Helix_Angle_Filter_Settings['Spatial Filter: Wall Depth Factor'] = 0.25\n",
    "Helix_Angle_Filter_Settings['Spatial Filter: Kernel Size']       = 5\n",
    "\n",
    "\n",
    "#mask is either GT or predicted!!, so need to run one for GT and one for pred!\n",
    "#split here... eg. make function out of above here, and then do the same for GT and prediciton.\n",
    "#....\n",
    "\n",
    "\n",
    "[Cardiac_DTI_Metrics, Epi, Endo, Mask] = cDTI_recon(myocardial_mask, Eigenvectors, num_interp_points, smoothness_level, Helix_Angle_Filter_Settings)\n",
    "\n",
    "myocardial_mask_smoothed = np.copy(Mask)\n",
    "#if native, smoothness and regular one should be equal\n",
    "if (myocardial_mask == myocardial_mask_smoothed):\n",
    "    print('smoothness level is set to native, so check should pass!')\n",
    "\n",
    "else:\n",
    "    print('some smoothenss is happneing on the masks.... double check')\n",
    "    #maybe set to low/ medium,  otherwise save as a new smoothed or something.. as an 07 folder in the orignal folder strucutre and then do the HAP assesmetnnow    \n",
    "    #if this trigers we have ot use the smoothed one for MD FA etc. too!\n",
    "    #could also save this as excel.. first check if trigger even happens.\n",
    "\n",
    "\n",
    "myocardial_mask_smoothed_nan = np.copy(myocardial_mask_smoothed)\n",
    "myocardial_mask_smoothed_nan = myocardial_mask_smoothed_nan.astype('float')\n",
    "\n",
    "myocardial_mask_smoothed_nan [myocardial_mask_smoothed_nan == 0] = np.nan\n",
    "\n",
    "grid     = Endo2Epi_Grid(myocardial_mask_smoothed)\n",
    "grid_nan = np.copy(grid)\n",
    "grid_nan = grid_nan * myocardial_mask_smoothed_nan\n",
    "grid_nan = np.clip(grid_nan, 0.0, 1)\n",
    "matrix   = matrix_sorted\n",
    "\n",
    "#what we want to save:\n",
    "#Standard_DTI_Metrics -> mat file, stored as a dictionary atm.\n",
    "#Cardiac_DTI_Metrics -> ^\n",
    "#for both GT and predicted!!! so need two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/saschastocker/Documents/Stanford/work2024/Paper2025Automatic/HAanalysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60050/1092582126.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/saschastocker/Documents/Stanford/work2024/Paper2025Automatic/HAanalysis'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvolunteer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvolunteer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Distortion_Corrected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/saschastocker/Documents/Stanford/work2024/Paper2025Automatic/HAanalysis'"
     ]
    }
   ],
   "source": [
    "main_path                = sample_Output_Folder()\n",
    "\n",
    "main_path = '/Users/saschastocker/Documents/Stanford/work2024/Paper2025Automatic/HAanalysis'\n",
    "\n",
    "for volunteer in os.listdir(main_path):\n",
    "    for dataset in os.listdir(os.path.join(main_path,volunteer,'Distortion_Corrected')):\n",
    "        dataset\n",
    "\n",
    "    \n",
    "NifTi_path               = glob.glob(os.path.join(main_path, '*Interpolated', '*.nii'))[0]\n",
    "header_path              = glob.glob(os.path.join(main_path, '*Interpolated', '*.header'))[0]\n",
    "b_values_path            = glob.glob(os.path.join(main_path, '*Interpolated', '*.bvals'))[0]\n",
    "b_vectors_path           = glob.glob(os.path.join(main_path, '*Interpolated', '*.bvecs'))[0]\n",
    "#map to the data we pull in from the orignal images from folders\n",
    "input_path_data = \"\"\n",
    "\n",
    "#use for later integration in the segmentaiotn analysis\n",
    "input_path_segmentation = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myocardial_mask_smoothed_nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60050/354332045.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mHAR_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mslc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyocardial_mask_smoothed_nan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mE2E_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_nan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mE2E_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE2E_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_nan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myocardial_mask_smoothed_nan' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "HAP_gt = []\n",
    "HAR_gt = []\n",
    "\n",
    "for slc in range(myocardial_mask_smoothed_nan.shape[2]):\n",
    "    E2E_data = grid_nan[:, :, slc].flatten()\n",
    "    E2E_data = E2E_data[~(np.isnan(grid_nan[:, :, slc].flatten()))]\n",
    "    x = E2E_data\n",
    "    xi = np.copy(x)\n",
    "\n",
    "\n",
    "\n",
    "    HA_data  = Cardiac_DTI_Metrics['HA'][:, :, slc].flatten()\n",
    "    HA_data  = HA_data[~(np.isnan(grid_nan[:, :, slc].flatten()))]\n",
    "    y = HA_data\n",
    "    yi = np.copy(y)\n",
    "\n",
    "    # Calculate the point density\n",
    "    xy = np.vstack([x, y])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "\n",
    "    # Sort the points by density, so that the densest points are plotted last\n",
    "    idx = z.argsort()\n",
    "    x, y, z = x[idx], y[idx], z[idx]\n",
    "    density = plt.scatter(x, y, c=z, s=50, cmap = 'hot')\n",
    "\n",
    "\n",
    "    model                 = LinearRegression().fit(x[:, np.newaxis], y[:, np.newaxis])\n",
    "    #enforcing true 0 and true 1, true epi and endo endpoint/limit\n",
    "    x_predicted = np.linspace(0,1, 101)\n",
    "    y_predicted = model.intercept_ + model.coef_ * x_predicted[:, np.newaxis]\n",
    "\n",
    "    #adds the helix angle pitches from each slice\n",
    "    HAP_gt.append(model.coef_)\n",
    "\n",
    "    #get the ranges, positive - (negative) -> range of the angles.\n",
    "    HAR_gt.append(y_predicted[0]-y_predicted[-1])\n",
    "\n",
    "\n",
    "# #repeat for predicted mask TODO!\n",
    "# HAP_pred..\n",
    "# HAR_pred....\n",
    "#compare -> similar to MD and FA maps comparison... should be super close otherwise the segmentation is off\n",
    "#can compare the pitches or the ranges, depending on what's more tellling/ better to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_predicted = np.linspace(0,1, 101)\n",
    "x_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
